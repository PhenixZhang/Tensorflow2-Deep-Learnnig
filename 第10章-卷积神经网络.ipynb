{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from  tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([2,5,5,3])\n",
    "w = tf.random.normal([3,3,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[0,0],[0,0],[0,0]])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.nn.conv2d(x,w,strides=1,padding=[[0,0],[1,1],[1,1],[0,0]])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.nn.conv2d(x,w,strides=1,padding=\"SAME\")\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2, 2, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.nn.conv2d(x,w,strides=3,padding=\"SAME\")\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[  1.2617452    0.7868017   10.631308    -3.9056907 ]\n",
      "   [ -1.0621094   -2.7451036    8.592527    -1.7331948 ]]\n",
      "\n",
      "  [[ -9.068312    -1.244396    -7.1816626    3.9098196 ]\n",
      "   [  2.4038322   -2.877333     4.322848    -2.8400054 ]]]\n",
      "\n",
      "\n",
      " [[[ -3.951347     4.201068   -10.864672     6.5969157 ]\n",
      "   [  1.5218661    1.3711784    0.01788038  -2.3165197 ]]\n",
      "\n",
      "  [[  1.2186751   -0.75807244   3.5617695   -0.37776738]\n",
      "   [ -1.8935605    0.13254738  -1.5031054   -0.47168088]]]], shape=(2, 2, 2, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[ 5.2617455   4.786802   14.631308    0.09430933]\n",
      "   [ 2.9378905   1.2548964  12.592527    2.2668052 ]]\n",
      "\n",
      "  [[-5.0683117   2.755604   -3.1816626   7.9098196 ]\n",
      "   [ 6.4038324   1.1226671   8.322847    1.1599946 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.04865289  8.201068   -6.8646717  10.596916  ]\n",
      "   [ 5.521866    5.3711786   4.0178804   1.6834803 ]]\n",
      "\n",
      "  [[ 5.218675    3.2419276   7.5617695   3.6222327 ]\n",
      "   [ 2.1064396   4.1325474   2.4968946   3.5283191 ]]]], shape=(2, 2, 2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.zeros([4])\n",
    "print(out)\n",
    "out = out + 4\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 5, 5, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Conv2D(4, kernel_size=3, strides=1, padding=\"SAME\")\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 3, 4) dtype=float32, numpy=\n",
       " array([[[[-0.13312691,  0.11174396, -0.30182788, -0.12716603],\n",
       "          [-0.17392473,  0.11252919, -0.22878462,  0.15242964],\n",
       "          [ 0.09085491, -0.17088701, -0.2628021 , -0.0999193 ]],\n",
       " \n",
       "         [[-0.10237268,  0.17628217, -0.10458486,  0.2774857 ],\n",
       "          [-0.19978416,  0.15922135,  0.16151029,  0.01040673],\n",
       "          [-0.16308425,  0.30388817,  0.07588512, -0.05970423]],\n",
       " \n",
       "         [[ 0.09681013, -0.17073984,  0.22532544, -0.30045557],\n",
       "          [ 0.13383731,  0.13836852,  0.07300881,  0.23909107],\n",
       "          [ 0.28176495, -0.16693677,  0.18085736,  0.205376  ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02772132,  0.05495715,  0.10449648, -0.06421924],\n",
       "          [ 0.25039312, -0.12093747,  0.10061195,  0.3074942 ],\n",
       "          [ 0.28521952,  0.3066444 , -0.12745821, -0.21059535]],\n",
       " \n",
       "         [[ 0.2644079 , -0.14695972, -0.26158476, -0.28864357],\n",
       "          [-0.2680601 ,  0.09786016,  0.22459552,  0.30586144],\n",
       "          [-0.14229138,  0.21476594,  0.28118   , -0.1701054 ]],\n",
       " \n",
       "         [[-0.23778492,  0.25397936, -0.25811976,  0.20218477],\n",
       "          [-0.15218616, -0.15537605,  0.28219214,  0.06248084],\n",
       "          [-0.06488791, -0.11178809,  0.13744467,  0.19476768]]],\n",
       " \n",
       " \n",
       "        [[[ 0.24376759,  0.286747  ,  0.27046636,  0.16146275],\n",
       "          [-0.30687243, -0.28057292,  0.14530438, -0.05895962],\n",
       "          [ 0.10802513,  0.19656655,  0.0220634 ,  0.21941611]],\n",
       " \n",
       "         [[-0.02348286,  0.10187331, -0.26105264, -0.22316836],\n",
       "          [ 0.27777126,  0.22630593, -0.2857744 , -0.10469045],\n",
       "          [ 0.10585502, -0.12448582,  0.09551972, -0.2116991 ]],\n",
       " \n",
       "         [[-0.12453401,  0.0877102 , -0.08481169,  0.09097633],\n",
       "          [ 0.3058968 ,  0.12606627, -0.15997222,  0.195914  ],\n",
       "          [-0.00576177,  0.16215417, -0.18305093,  0.22523823]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_3/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 3, 4) dtype=float32, numpy=\n",
       " array([[[[-0.13312691,  0.11174396, -0.30182788, -0.12716603],\n",
       "          [-0.17392473,  0.11252919, -0.22878462,  0.15242964],\n",
       "          [ 0.09085491, -0.17088701, -0.2628021 , -0.0999193 ]],\n",
       " \n",
       "         [[-0.10237268,  0.17628217, -0.10458486,  0.2774857 ],\n",
       "          [-0.19978416,  0.15922135,  0.16151029,  0.01040673],\n",
       "          [-0.16308425,  0.30388817,  0.07588512, -0.05970423]],\n",
       " \n",
       "         [[ 0.09681013, -0.17073984,  0.22532544, -0.30045557],\n",
       "          [ 0.13383731,  0.13836852,  0.07300881,  0.23909107],\n",
       "          [ 0.28176495, -0.16693677,  0.18085736,  0.205376  ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02772132,  0.05495715,  0.10449648, -0.06421924],\n",
       "          [ 0.25039312, -0.12093747,  0.10061195,  0.3074942 ],\n",
       "          [ 0.28521952,  0.3066444 , -0.12745821, -0.21059535]],\n",
       " \n",
       "         [[ 0.2644079 , -0.14695972, -0.26158476, -0.28864357],\n",
       "          [-0.2680601 ,  0.09786016,  0.22459552,  0.30586144],\n",
       "          [-0.14229138,  0.21476594,  0.28118   , -0.1701054 ]],\n",
       " \n",
       "         [[-0.23778492,  0.25397936, -0.25811976,  0.20218477],\n",
       "          [-0.15218616, -0.15537605,  0.28219214,  0.06248084],\n",
       "          [-0.06488791, -0.11178809,  0.13744467,  0.19476768]]],\n",
       " \n",
       " \n",
       "        [[[ 0.24376759,  0.286747  ,  0.27046636,  0.16146275],\n",
       "          [-0.30687243, -0.28057292,  0.14530438, -0.05895962],\n",
       "          [ 0.10802513,  0.19656655,  0.0220634 ,  0.21941611]],\n",
       " \n",
       "         [[-0.02348286,  0.10187331, -0.26105264, -0.22316836],\n",
       "          [ 0.27777126,  0.22630593, -0.2857744 , -0.10469045],\n",
       "          [ 0.10585502, -0.12448582,  0.09551972, -0.2116991 ]],\n",
       " \n",
       "         [[-0.12453401,  0.0877102 , -0.08481169,  0.09097633],\n",
       "          [ 0.3058968 ,  0.12606627, -0.15997222,  0.195914  ],\n",
       "          [-0.00576177,  0.16215417, -0.18305093,  0.22523823]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_3/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.kernel,layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (4, 26, 26, 6)            60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (4, 13, 13, 6)            0         \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (4, 13, 13, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (4, 11, 11, 16)           880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (4, 5, 5, 16)             0         \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (4, 5, 5, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (4, 400)                  0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (4, 120)                  48120     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (4, 84)                   10164     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (4, 10)                   850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LeNEt-5\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "network = Sequential([\n",
    "    layers.Conv2D(6,kernel_size=3, strides=1),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(16,kernel_size=3, strides=1),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.ReLU(),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(120, activation = 'relu'),\n",
    "    layers.Dense(84, activation = 'relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "network.build(input_shape=(4, 28, 28, 1))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (60000, 28, 28) y: (60000,) x test: (10000, 28, 28) y test: [7 2 1 ... 4 5 6]\n",
      "train_acc: 0.19491666666666665\n",
      "train_acc: 0.2692\n",
      "train_acc: 0.2872166666666667\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets, layers, optimizers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "criteon = losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = optimizers.Adam()\n",
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "print('x:', x.shape, 'y:', y.shape, 'x test:', x_test.shape, 'y test:', y_test)\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # [0~1]\n",
    "    x = 2*tf.cast(x, dtype=tf.float32) / 255.-1\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "# 构建训练集对象\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.shuffle(1000).batch(128)\n",
    "# 构建测试集对象\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.map(preprocess).batch(128)\n",
    "\n",
    "for i in range(3):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x = tf.expand_dims(x, axis=3)\n",
    "        out = network(x)\n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        loss = criteon(y_onehot, out)\n",
    "\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "    correct, total = 0,0\n",
    "\n",
    "    for x,y in train_db:\n",
    "        x = tf.expand_dims(x,axis=3)\n",
    "        out = network(x)\n",
    "        pred = tf.argmax(out, axis=-1)\n",
    "        y = tf.cast(y, tf.int64)\n",
    "        correct += float(tf.reduce_sum(tf.cast(tf.equal(pred,y),tf.float32)))\n",
    "        total += x.shape[0]\n",
    "\n",
    "    print('train_acc:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.1496\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0,0\n",
    "\n",
    "for x,y in test_db:\n",
    "    x = tf.expand_dims(x,axis=3)\n",
    "    out = network(x)\n",
    "    pred = tf.argmax(out, axis=-1)\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    correct += float(tf.reduce_sum(tf.cast(tf.equal(pred,y),tf.float32)))\n",
    "    total += x.shape[0]\n",
    "\n",
    "print('test_acc:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([100, 32, 32, 3])\n",
    "x = tf.reshape(x, [-1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([102400, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub = tf.reduce_mean(x, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.00021444, -0.00204687, -0.00099128], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "layer = layers.BatchNormalization()\n",
    "\n",
    "network = Sequential([\n",
    "    layers.Conv2D(6, kernel_size=3, strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=2,strides=2),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(16, kernel_size=3, strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "    layers.ReLU(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "network.build(input_shape=(4, 28, 28, 1))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    x = tf.expand_dims(x, axis=3)\n",
    "    out = network(x, training = True)\n",
    "    \n",
    "for x,y in test_db:\n",
    "    x = tf.expand_dims(x,axis=3)\n",
    "    out = network(x, training=False)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
