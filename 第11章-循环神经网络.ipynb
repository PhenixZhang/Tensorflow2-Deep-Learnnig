{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.keras import layers, Sequential, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 8 4 5 9 3 2 6 7 0], shape=(10,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-0.04104223  0.03661125 -0.02370019 -0.03036099  0.00773614  0.01967012\n",
      "   0.01004293 -0.04373357 -0.0409      0.02145486 -0.04148582 -0.01358209\n",
      "  -0.0466767   0.02156265  0.04181829  0.01141511  0.0442355   0.01730238\n",
      "   0.03390783  0.03080847 -0.02698643  0.00875882  0.010825   -0.01409436\n",
      "  -0.01836531 -0.0246737   0.02806444 -0.03427326 -0.0112129   0.00909882\n",
      "   0.01091373  0.01016245 -0.00542359 -0.00608736  0.02559236  0.01436975\n",
      "  -0.03503488  0.01988143 -0.01447881  0.01518646  0.00454659 -0.04424958\n",
      "  -0.03936644 -0.04577525 -0.02779775  0.03399304  0.04801447 -0.03898401\n",
      "   0.01959674  0.00158527]\n",
      " [ 0.04222841  0.0127858   0.02201172 -0.0036354   0.00950322 -0.00115615\n",
      "  -0.00958993  0.04028288  0.03263043 -0.04670949 -0.02430674  0.04813853\n",
      "  -0.01745922  0.02305155 -0.03053217 -0.04161077  0.01449535  0.04767524\n",
      "  -0.00613078 -0.01173099  0.03007326  0.03098941 -0.01321596  0.040491\n",
      "  -0.03967836  0.04796649 -0.04611056  0.00231129 -0.03035739  0.02838821\n",
      "  -0.00229841  0.04056204 -0.01432319  0.02685393  0.00245706  0.02666355\n",
      "   0.00219184 -0.00707371  0.01796016 -0.00519365 -0.01635231  0.00910931\n",
      "  -0.01673923 -0.00556195  0.04718646 -0.02578156  0.0352729   0.02290721\n",
      "  -0.0116279  -0.03466362]\n",
      " [-0.03268057  0.04993219 -0.01125051  0.00577643  0.01569134 -0.03051364\n",
      "  -0.03663782 -0.024604   -0.03099691 -0.01278083 -0.03716396  0.01396755\n",
      "   0.03399357 -0.02221935  0.03719479 -0.01524265 -0.02690563  0.04077132\n",
      "  -0.030764    0.00080407  0.04628732  0.04001068  0.03162118 -0.02062463\n",
      "  -0.02952901  0.02901019  0.03571167 -0.01051382  0.03411918 -0.01066755\n",
      "   0.03917337  0.04403018  0.04730216  0.03444559 -0.0468186   0.00148102\n",
      "  -0.04579141 -0.02925215  0.01126979 -0.02264187 -0.04996977  0.01391692\n",
      "  -0.02418551 -0.01576163 -0.00407503 -0.00907004 -0.02076157  0.00042689\n",
      "  -0.03337048 -0.04708714]\n",
      " [ 0.0082956   0.04762644  0.01790769  0.01301854 -0.00429956 -0.02153581\n",
      "   0.00047529 -0.00638689  0.03049945  0.04212036 -0.02860823 -0.00341556\n",
      "  -0.02548897  0.01634214  0.03275794  0.03441227 -0.03579999  0.04159879\n",
      "  -0.03459011 -0.02199416 -0.01494537 -0.04380598  0.02747342  0.00396841\n",
      "  -0.00438754  0.04649175  0.04164309 -0.02004108  0.00416445  0.02391434\n",
      "  -0.02427719  0.00351312  0.04699048 -0.0107765  -0.01225424 -0.04378331\n",
      "   0.0290588  -0.03760725  0.04533188  0.01158587  0.00060977 -0.0412663\n",
      "   0.00841587  0.0059744  -0.00844648 -0.00057334 -0.04252183 -0.02295979\n",
      "   0.0383854  -0.02625064]\n",
      " [-0.01283322 -0.01737478 -0.02648584 -0.03212403  0.03892301 -0.03076369\n",
      "  -0.01144079  0.02807811  0.02448127  0.0073872   0.04491818 -0.00897362\n",
      "   0.04504892  0.02176323 -0.03609844 -0.0345484  -0.04781744  0.03185968\n",
      "   0.01329173  0.02793046  0.01082898  0.00059485  0.04479193  0.0262018\n",
      "   0.00497699 -0.03007029 -0.04334446 -0.01515756  0.03936206  0.02495446\n",
      "  -0.02836825 -0.00697722 -0.03026017 -0.03927571 -0.0212882  -0.03005909\n",
      "   0.02613154  0.01038525 -0.03630899 -0.03870936 -0.02773706 -0.01374168\n",
      "   0.03713107 -0.00609225 -0.03132175  0.02368715 -0.02394125  0.03366257\n",
      "  -0.03260138  0.04879744]\n",
      " [ 0.02520135  0.01273418  0.01811901  0.00785208  0.04473307 -0.04257475\n",
      "  -0.01938895 -0.04811507 -0.03048658  0.02245076 -0.0428555   0.01374647\n",
      "  -0.0038263  -0.00626814  0.00519693 -0.04994715  0.04043164 -0.00870341\n",
      "  -0.01603733 -0.00248828 -0.01218409  0.0272075   0.01467401 -0.02665585\n",
      "  -0.04627002 -0.00691584 -0.02280654 -0.02386477  0.01692886  0.00763779\n",
      "  -0.00647175  0.01977572 -0.00759145  0.00334178  0.01856357  0.03463538\n",
      "  -0.03243979  0.01657549  0.00843474 -0.0255006   0.00714457  0.00691676\n",
      "  -0.03693968  0.04451955 -0.02614601 -0.01914427 -0.03617696 -0.04767424\n",
      "  -0.04758952  0.00078534]\n",
      " [-0.00300545 -0.02599431 -0.02029585 -0.0430222  -0.00926248  0.00112698\n",
      "  -0.00846846  0.03574133 -0.04471507  0.00814275 -0.0011718   0.01959293\n",
      "  -0.01276686  0.03944497  0.00859761  0.0324635   0.01619716 -0.02484987\n",
      "  -0.00266965  0.01037885 -0.03585211  0.01523683  0.02543601 -0.03605551\n",
      "  -0.00014602  0.03900453  0.0194697  -0.03211608 -0.0150733   0.03884328\n",
      "  -0.03691814 -0.00261436 -0.00285944  0.01248958  0.00362837 -0.04246587\n",
      "  -0.0243417   0.03842125  0.02055806  0.02373166  0.01799357 -0.01097446\n",
      "   0.03423551  0.02411381  0.04862345  0.03186193  0.04934528  0.02801606\n",
      "  -0.00548661  0.01987575]\n",
      " [-0.00215675  0.00746906  0.03427118 -0.03027523 -0.00439173  0.01224748\n",
      "   0.02094269 -0.02105259  0.04351287 -0.03431431  0.0221015  -0.02752842\n",
      "  -0.02702758 -0.01949788  0.03427241  0.04456406  0.03653688  0.02755998\n",
      "  -0.00585531  0.00992619 -0.02746607 -0.03879565 -0.01950992  0.02175574\n",
      "   0.04036887 -0.01367314 -0.03573896 -0.04014963  0.00057488  0.04695996\n",
      "  -0.04747846  0.02675522  0.03468681 -0.00687921 -0.04319357 -0.02312135\n",
      "   0.00250919 -0.03825853 -0.01670743  0.02802924  0.01980919  0.02853382\n",
      "   0.03712858 -0.04811469  0.04397542  0.02944324  0.03664584  0.01324158\n",
      "   0.04383883  0.03888246]\n",
      " [-0.03444823 -0.04175382  0.00705103  0.02532652  0.01252982  0.01695839\n",
      "  -0.00839058 -0.04994902 -0.00898205  0.03519822 -0.00854412 -0.03744885\n",
      "   0.01194109  0.02788873  0.04982216 -0.04057347  0.04989145 -0.02804544\n",
      "   0.03706146 -0.03929908  0.04050995  0.04774066 -0.03444997  0.02633457\n",
      "   0.02354796  0.02054757  0.00741863  0.04177522  0.04009098 -0.02065892\n",
      "  -0.0465849  -0.02658527 -0.00659672  0.03434563  0.00011145 -0.04250918\n",
      "  -0.03632166 -0.04548714  0.00885047  0.04281035 -0.02273165  0.02903939\n",
      "   0.03917779 -0.04944894  0.01672569 -0.0325196   0.00919307 -0.03922056\n",
      "  -0.01584492  0.00058744]\n",
      " [ 0.00288099  0.04093314  0.00774022 -0.04573673 -0.0352148   0.02801606\n",
      "  -0.02008263  0.01844342  0.01915607  0.04131806  0.01928978  0.02253431\n",
      "  -0.0108984   0.04860235  0.04769845 -0.03932257 -0.01801757 -0.04928768\n",
      "   0.00990806  0.04626575 -0.00939219 -0.01106798 -0.02940609  0.02184192\n",
      "   0.0321139  -0.02477725 -0.01876075 -0.01835389  0.00442781  0.01036303\n",
      "   0.00447699 -0.03889607 -0.02960066  0.03158193  0.01083461 -0.00985352\n",
      "   0.01233481 -0.02409931 -0.02112718  0.01087176  0.02573014 -0.02336495\n",
      "   0.00243124 -0.01027447 -0.04126956 -0.0423066  -0.01543009  0.00337906\n",
      "   0.01790905  0.00446013]], shape=(10, 50), dtype=float32)\n",
      "<tf.Variable 'embedding_1/embeddings:0' shape=(10, 50) dtype=float32, numpy=\n",
      "array([[ 0.00288099,  0.04093314,  0.00774022, -0.04573673, -0.0352148 ,\n",
      "         0.02801606, -0.02008263,  0.01844342,  0.01915607,  0.04131806,\n",
      "         0.01928978,  0.02253431, -0.0108984 ,  0.04860235,  0.04769845,\n",
      "        -0.03932257, -0.01801757, -0.04928768,  0.00990806,  0.04626575,\n",
      "        -0.00939219, -0.01106798, -0.02940609,  0.02184192,  0.0321139 ,\n",
      "        -0.02477725, -0.01876075, -0.01835389,  0.00442781,  0.01036303,\n",
      "         0.00447699, -0.03889607, -0.02960066,  0.03158193,  0.01083461,\n",
      "        -0.00985352,  0.01233481, -0.02409931, -0.02112718,  0.01087176,\n",
      "         0.02573014, -0.02336495,  0.00243124, -0.01027447, -0.04126956,\n",
      "        -0.0423066 , -0.01543009,  0.00337906,  0.01790905,  0.00446013],\n",
      "       [-0.04104223,  0.03661125, -0.02370019, -0.03036099,  0.00773614,\n",
      "         0.01967012,  0.01004293, -0.04373357, -0.0409    ,  0.02145486,\n",
      "        -0.04148582, -0.01358209, -0.0466767 ,  0.02156265,  0.04181829,\n",
      "         0.01141511,  0.0442355 ,  0.01730238,  0.03390783,  0.03080847,\n",
      "        -0.02698643,  0.00875882,  0.010825  , -0.01409436, -0.01836531,\n",
      "        -0.0246737 ,  0.02806444, -0.03427326, -0.0112129 ,  0.00909882,\n",
      "         0.01091373,  0.01016245, -0.00542359, -0.00608736,  0.02559236,\n",
      "         0.01436975, -0.03503488,  0.01988143, -0.01447881,  0.01518646,\n",
      "         0.00454659, -0.04424958, -0.03936644, -0.04577525, -0.02779775,\n",
      "         0.03399304,  0.04801447, -0.03898401,  0.01959674,  0.00158527],\n",
      "       [-0.00300545, -0.02599431, -0.02029585, -0.0430222 , -0.00926248,\n",
      "         0.00112698, -0.00846846,  0.03574133, -0.04471507,  0.00814275,\n",
      "        -0.0011718 ,  0.01959293, -0.01276686,  0.03944497,  0.00859761,\n",
      "         0.0324635 ,  0.01619716, -0.02484987, -0.00266965,  0.01037885,\n",
      "        -0.03585211,  0.01523683,  0.02543601, -0.03605551, -0.00014602,\n",
      "         0.03900453,  0.0194697 , -0.03211608, -0.0150733 ,  0.03884328,\n",
      "        -0.03691814, -0.00261436, -0.00285944,  0.01248958,  0.00362837,\n",
      "        -0.04246587, -0.0243417 ,  0.03842125,  0.02055806,  0.02373166,\n",
      "         0.01799357, -0.01097446,  0.03423551,  0.02411381,  0.04862345,\n",
      "         0.03186193,  0.04934528,  0.02801606, -0.00548661,  0.01987575],\n",
      "       [ 0.02520135,  0.01273418,  0.01811901,  0.00785208,  0.04473307,\n",
      "        -0.04257475, -0.01938895, -0.04811507, -0.03048658,  0.02245076,\n",
      "        -0.0428555 ,  0.01374647, -0.0038263 , -0.00626814,  0.00519693,\n",
      "        -0.04994715,  0.04043164, -0.00870341, -0.01603733, -0.00248828,\n",
      "        -0.01218409,  0.0272075 ,  0.01467401, -0.02665585, -0.04627002,\n",
      "        -0.00691584, -0.02280654, -0.02386477,  0.01692886,  0.00763779,\n",
      "        -0.00647175,  0.01977572, -0.00759145,  0.00334178,  0.01856357,\n",
      "         0.03463538, -0.03243979,  0.01657549,  0.00843474, -0.0255006 ,\n",
      "         0.00714457,  0.00691676, -0.03693968,  0.04451955, -0.02614601,\n",
      "        -0.01914427, -0.03617696, -0.04767424, -0.04758952,  0.00078534],\n",
      "       [-0.03268057,  0.04993219, -0.01125051,  0.00577643,  0.01569134,\n",
      "        -0.03051364, -0.03663782, -0.024604  , -0.03099691, -0.01278083,\n",
      "        -0.03716396,  0.01396755,  0.03399357, -0.02221935,  0.03719479,\n",
      "        -0.01524265, -0.02690563,  0.04077132, -0.030764  ,  0.00080407,\n",
      "         0.04628732,  0.04001068,  0.03162118, -0.02062463, -0.02952901,\n",
      "         0.02901019,  0.03571167, -0.01051382,  0.03411918, -0.01066755,\n",
      "         0.03917337,  0.04403018,  0.04730216,  0.03444559, -0.0468186 ,\n",
      "         0.00148102, -0.04579141, -0.02925215,  0.01126979, -0.02264187,\n",
      "        -0.04996977,  0.01391692, -0.02418551, -0.01576163, -0.00407503,\n",
      "        -0.00907004, -0.02076157,  0.00042689, -0.03337048, -0.04708714],\n",
      "       [ 0.0082956 ,  0.04762644,  0.01790769,  0.01301854, -0.00429956,\n",
      "        -0.02153581,  0.00047529, -0.00638689,  0.03049945,  0.04212036,\n",
      "        -0.02860823, -0.00341556, -0.02548897,  0.01634214,  0.03275794,\n",
      "         0.03441227, -0.03579999,  0.04159879, -0.03459011, -0.02199416,\n",
      "        -0.01494537, -0.04380598,  0.02747342,  0.00396841, -0.00438754,\n",
      "         0.04649175,  0.04164309, -0.02004108,  0.00416445,  0.02391434,\n",
      "        -0.02427719,  0.00351312,  0.04699048, -0.0107765 , -0.01225424,\n",
      "        -0.04378331,  0.0290588 , -0.03760725,  0.04533188,  0.01158587,\n",
      "         0.00060977, -0.0412663 ,  0.00841587,  0.0059744 , -0.00844648,\n",
      "        -0.00057334, -0.04252183, -0.02295979,  0.0383854 , -0.02625064],\n",
      "       [-0.00215675,  0.00746906,  0.03427118, -0.03027523, -0.00439173,\n",
      "         0.01224748,  0.02094269, -0.02105259,  0.04351287, -0.03431431,\n",
      "         0.0221015 , -0.02752842, -0.02702758, -0.01949788,  0.03427241,\n",
      "         0.04456406,  0.03653688,  0.02755998, -0.00585531,  0.00992619,\n",
      "        -0.02746607, -0.03879565, -0.01950992,  0.02175574,  0.04036887,\n",
      "        -0.01367314, -0.03573896, -0.04014963,  0.00057488,  0.04695996,\n",
      "        -0.04747846,  0.02675522,  0.03468681, -0.00687921, -0.04319357,\n",
      "        -0.02312135,  0.00250919, -0.03825853, -0.01670743,  0.02802924,\n",
      "         0.01980919,  0.02853382,  0.03712858, -0.04811469,  0.04397542,\n",
      "         0.02944324,  0.03664584,  0.01324158,  0.04383883,  0.03888246],\n",
      "       [-0.03444823, -0.04175382,  0.00705103,  0.02532652,  0.01252982,\n",
      "         0.01695839, -0.00839058, -0.04994902, -0.00898205,  0.03519822,\n",
      "        -0.00854412, -0.03744885,  0.01194109,  0.02788873,  0.04982216,\n",
      "        -0.04057347,  0.04989145, -0.02804544,  0.03706146, -0.03929908,\n",
      "         0.04050995,  0.04774066, -0.03444997,  0.02633457,  0.02354796,\n",
      "         0.02054757,  0.00741863,  0.04177522,  0.04009098, -0.02065892,\n",
      "        -0.0465849 , -0.02658527, -0.00659672,  0.03434563,  0.00011145,\n",
      "        -0.04250918, -0.03632166, -0.04548714,  0.00885047,  0.04281035,\n",
      "        -0.02273165,  0.02903939,  0.03917779, -0.04944894,  0.01672569,\n",
      "        -0.0325196 ,  0.00919307, -0.03922056, -0.01584492,  0.00058744],\n",
      "       [ 0.04222841,  0.0127858 ,  0.02201172, -0.0036354 ,  0.00950322,\n",
      "        -0.00115615, -0.00958993,  0.04028288,  0.03263043, -0.04670949,\n",
      "        -0.02430674,  0.04813853, -0.01745922,  0.02305155, -0.03053217,\n",
      "        -0.04161077,  0.01449535,  0.04767524, -0.00613078, -0.01173099,\n",
      "         0.03007326,  0.03098941, -0.01321596,  0.040491  , -0.03967836,\n",
      "         0.04796649, -0.04611056,  0.00231129, -0.03035739,  0.02838821,\n",
      "        -0.00229841,  0.04056204, -0.01432319,  0.02685393,  0.00245706,\n",
      "         0.02666355,  0.00219184, -0.00707371,  0.01796016, -0.00519365,\n",
      "        -0.01635231,  0.00910931, -0.01673923, -0.00556195,  0.04718646,\n",
      "        -0.02578156,  0.0352729 ,  0.02290721, -0.0116279 , -0.03466362],\n",
      "       [-0.01283322, -0.01737478, -0.02648584, -0.03212403,  0.03892301,\n",
      "        -0.03076369, -0.01144079,  0.02807811,  0.02448127,  0.0073872 ,\n",
      "         0.04491818, -0.00897362,  0.04504892,  0.02176323, -0.03609844,\n",
      "        -0.0345484 , -0.04781744,  0.03185968,  0.01329173,  0.02793046,\n",
      "         0.01082898,  0.00059485,  0.04479193,  0.0262018 ,  0.00497699,\n",
      "        -0.03007029, -0.04334446, -0.01515756,  0.03936206,  0.02495446,\n",
      "        -0.02836825, -0.00697722, -0.03026017, -0.03927571, -0.0212882 ,\n",
      "        -0.03005909,  0.02613154,  0.01038525, -0.03630899, -0.03870936,\n",
      "        -0.02773706, -0.01374168,  0.03713107, -0.00609225, -0.03132175,\n",
      "         0.02368715, -0.02394125,  0.03366257, -0.03260138,  0.04879744]],\n",
      "      dtype=float32)>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = tf.range(10)\n",
    "x = tf.random.shuffle(x)\n",
    "net = layers.Embedding(10, 50)\n",
    "out = net(x)\n",
    "print(x)\n",
    "print(out)\n",
    "print(net.embeddings)\n",
    "print(net.embeddings.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe!\n"
     ]
    }
   ],
   "source": [
    "filename = 'glove.6B.50d.txt'\n",
    "def loadGloVe(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    emb_size = 50\n",
    "    vocab.append('unk') #装载不认识的词\n",
    "    embd.append([0]*emb_size) #这个emb_size可能需要指定\n",
    "    file = open(filename,'r')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded GloVe!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "vocab,embd = loadGloVe(filename)\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = len(embd[0])\n",
    "embedding = np.asarray(embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 16], [5, 36], [42, 37], [20, 36], [9], [36], [9, 5], [20, 36], [32, 36, 16, 42]]\n",
      "[[ 4 16  0  0]\n",
      " [ 5 36  0  0]\n",
      " [42 37  0  0]\n",
      " [20 36  0  0]\n",
      " [ 9  0  0  0]\n",
      " [36  0  0  0]\n",
      " [ 9  5  0  0]\n",
      " [20 36  0  0]\n",
      " [32 36 16 42]]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import one_hot\n",
    "#定义文档\n",
    "docs = [\n",
    "    'Well done',\n",
    "    'good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent',\n",
    "    'Weak',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'could have done better'\n",
    "]\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0])\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d,vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "max_len = max([len(v.split())for v in docs])\n",
    "padded_docs = pad_sequences(encoded_docs,maxlen=max_len,padding='post')\n",
    "print(padded_docs)\n",
    "\n",
    "#定义模型\n",
    "from tensorflow.keras import layers\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size,8,input_length=max_len))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "#编译模型\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6979 - acc: 0.3333\n",
      "Accuracy:33.333334\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs,labels)\n",
    "print('Accuracy:%f'%(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.6979 - acc: 0.3333\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6963 - acc: 0.3333\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6947 - acc: 0.3333\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - acc: 0.3333\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 0.4444\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 0.4444\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6883 - acc: 0.5556\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6868 - acc: 0.6667\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6852 - acc: 0.7778\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6837 - acc: 0.8889\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6821 - acc: 0.8889\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6806 - acc: 0.8889\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6791 - acc: 0.8889\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6775 - acc: 0.8889\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6760 - acc: 0.8889\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6745 - acc: 0.8889\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6730 - acc: 0.8889\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6714 - acc: 0.7778\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6699 - acc: 0.7778\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6684 - acc: 0.7778\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6669 - acc: 0.7778\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6653 - acc: 0.7778\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6638 - acc: 0.7778\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6622 - acc: 0.7778\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6607 - acc: 0.7778\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6591 - acc: 0.7778\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6575 - acc: 0.7778\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6559 - acc: 0.7778\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6543 - acc: 0.7778\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6527 - acc: 0.7778\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6511 - acc: 0.7778\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6495 - acc: 0.7778\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6479 - acc: 0.7778\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6462 - acc: 0.7778\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6446 - acc: 0.7778\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6429 - acc: 0.7778\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6412 - acc: 0.7778\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6395 - acc: 0.7778\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6378 - acc: 0.7778\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6361 - acc: 0.7778\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6343 - acc: 0.7778\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6326 - acc: 0.7778\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6308 - acc: 0.7778\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6290 - acc: 0.7778\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6273 - acc: 0.7778\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6255 - acc: 0.7778\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6237 - acc: 0.7778\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6218 - acc: 0.7778\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6200 - acc: 0.7778\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6182 - acc: 0.7778\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6163 - acc: 0.7778\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6144 - acc: 0.7778\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6125 - acc: 0.7778\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6107 - acc: 0.7778\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6087 - acc: 0.7778\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6068 - acc: 0.7778\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6049 - acc: 0.7778\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6030 - acc: 0.7778\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6010 - acc: 0.7778\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5991 - acc: 0.7778\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5971 - acc: 0.7778\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5951 - acc: 0.7778\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5931 - acc: 0.7778\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5911 - acc: 0.7778\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5891 - acc: 0.7778\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5871 - acc: 0.7778\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5851 - acc: 0.7778\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5831 - acc: 0.7778\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5810 - acc: 0.7778\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5790 - acc: 0.7778\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5769 - acc: 0.7778\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5749 - acc: 0.7778\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5728 - acc: 0.7778\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5708 - acc: 0.7778\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5687 - acc: 0.7778\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5666 - acc: 0.7778\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5645 - acc: 0.7778\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5624 - acc: 0.7778\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5603 - acc: 0.7778\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5582 - acc: 0.7778\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5561 - acc: 0.7778\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5540 - acc: 0.7778\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5518 - acc: 0.7778\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5497 - acc: 0.7778\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5476 - acc: 0.7778\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5454 - acc: 0.7778\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5433 - acc: 0.7778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5412 - acc: 0.7778\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5390 - acc: 0.8889\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5369 - acc: 0.8889\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5347 - acc: 0.8889\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5326 - acc: 0.8889\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5304 - acc: 0.8889\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5282 - acc: 0.8889\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5261 - acc: 0.8889\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5239 - acc: 0.8889\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5218 - acc: 0.8889\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5196 - acc: 0.8889\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5174 - acc: 0.8889\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5152 - acc: 0.8889\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5131 - acc: 0.8889\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5109 - acc: 0.8889\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5087 - acc: 0.8889\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5065 - acc: 0.8889\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5044 - acc: 0.8889\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5022 - acc: 0.8889\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5000 - acc: 0.8889\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4978 - acc: 0.8889\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4957 - acc: 0.8889\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - acc: 0.8889\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4913 - acc: 0.8889\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4891 - acc: 0.8889\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4869 - acc: 0.8889\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4848 - acc: 0.8889\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4826 - acc: 0.8889\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4804 - acc: 0.8889\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4782 - acc: 0.8889\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4760 - acc: 0.8889\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4739 - acc: 0.8889\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4717 - acc: 0.8889\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4695 - acc: 0.8889\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4673 - acc: 0.8889\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4652 - acc: 0.8889\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4630 - acc: 0.8889\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4608 - acc: 0.8889\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4587 - acc: 0.8889\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4565 - acc: 0.8889\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4543 - acc: 0.8889\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4522 - acc: 0.8889\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4500 - acc: 0.8889\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4478 - acc: 0.8889\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4457 - acc: 0.8889\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4435 - acc: 0.8889\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4414 - acc: 0.8889\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4392 - acc: 0.8889\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4371 - acc: 0.8889\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4349 - acc: 0.8889\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4328 - acc: 0.8889\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4307 - acc: 0.8889\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4285 - acc: 0.8889\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4264 - acc: 0.8889\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4243 - acc: 0.8889\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4222 - acc: 0.8889\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4200 - acc: 0.8889\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - acc: 0.8889\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4158 - acc: 0.8889\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4137 - acc: 0.8889\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4116 - acc: 0.8889\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4095 - acc: 0.8889\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4074 - acc: 0.8889\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(\n",
    "    padded_docs,\n",
    "    labels,\n",
    "    epochs=150\n",
    ")\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.plot(epochs,acc,label = 'Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs,loss,label = 'Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[-0.04824024, -0.866671  , -0.01306361],\n",
       "        [-0.69604814, -0.53313726, -0.8953723 ],\n",
       "        [-0.12791592,  0.8019912 , -0.6612742 ],\n",
       "        [-0.10096687,  0.74701846,  0.18305457]], dtype=float32)>,\n",
       " <tf.Variable 'recurrent_kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[-0.04335666,  0.74322754,  0.66763234],\n",
       "        [-0.64718276, -0.5299866 ,  0.54796773],\n",
       "        [ 0.76110095, -0.4083221 ,  0.50398254]], dtype=float32)>,\n",
       " <tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = layers.SimpleRNNCell(3)\n",
    "cell.build(input_shape=(None,4))\n",
    "cell.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 64) (4, 64)\n",
      "140456481582240 140456481582240\n"
     ]
    }
   ],
   "source": [
    "h0 = [tf.zeros([4,64])]\n",
    "x = tf.random.normal([4,80,100])\n",
    "xt = x[:,0,:]\n",
    "cell = layers.SimpleRNNCell(64)\n",
    "out, h1 = cell(xt, h0)\n",
    "print(out.shape, h1[0].shape)\n",
    "print(id(out),id(h1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 64), dtype=float32, numpy=\n",
       "array([[-0.622794  , -0.7578877 ,  0.7247572 , -0.51580095,  0.6263628 ,\n",
       "        -0.19127905, -0.62595516,  0.69797915, -0.01084008, -0.7604019 ,\n",
       "        -0.36244857,  0.9124519 ,  0.83474785, -0.41350278,  0.783318  ,\n",
       "        -0.19957668,  0.40632552,  0.8233092 ,  0.99818134, -0.978804  ,\n",
       "        -0.9040894 , -0.94575936,  0.77196866,  0.8785654 , -0.8286943 ,\n",
       "        -0.63247144, -0.9687763 , -0.8112018 ,  0.95671636, -0.448426  ,\n",
       "         0.9248826 ,  0.510795  , -0.5113191 ,  0.47816586,  0.90293217,\n",
       "         0.05577772, -0.68908703,  0.57003653,  0.9989039 ,  0.17570761,\n",
       "         0.37626356, -0.5326265 , -0.04508969, -0.9354595 ,  0.87394375,\n",
       "        -0.23534876, -0.68192005,  0.14333229,  0.9232905 ,  0.888446  ,\n",
       "         0.5402215 ,  0.05540015, -0.43938404, -0.24877436,  0.85240513,\n",
       "        -0.9675758 , -0.00203971,  0.9385038 ,  0.99153566,  0.9138791 ,\n",
       "         0.9936421 , -0.81869364, -0.8762752 ,  0.9332481 ],\n",
       "       [-0.3444609 ,  0.66478014, -0.07277972, -0.00758935,  0.7421261 ,\n",
       "         0.89575243, -0.33286712, -0.98196757,  0.9664144 ,  0.77427113,\n",
       "        -0.7449993 , -0.9851968 ,  0.15419635, -0.38149667, -0.8650991 ,\n",
       "        -0.5660952 , -0.8722814 , -0.8955356 , -0.7256018 , -0.35605732,\n",
       "        -0.63129693, -0.02244802,  0.7246519 , -0.99399936, -0.97784716,\n",
       "        -0.19766428,  0.89679325, -0.7985947 , -0.9658335 , -0.30972266,\n",
       "         0.8591194 ,  0.11989872, -0.9696544 ,  0.73814255,  0.32115403,\n",
       "         0.9949863 ,  0.88232416, -0.9681272 ,  0.99234504, -0.81361353,\n",
       "         0.7514257 , -0.04451073,  0.7543569 ,  0.8661221 , -0.99963576,\n",
       "         0.36660588,  0.85916144, -0.5898689 , -0.97842246, -0.24146973,\n",
       "         0.01776904,  0.32328847, -0.14514674, -0.9288396 ,  0.71933824,\n",
       "        -0.45433214,  0.48237163,  0.19083364, -0.8989839 ,  0.8511518 ,\n",
       "        -0.43830878,  0.11555042, -0.95790756, -0.6996842 ],\n",
       "       [-0.74798274,  0.30796507, -0.9680088 , -0.7495162 , -0.9454684 ,\n",
       "        -0.82574844,  0.9544929 ,  0.03972067, -0.47184888,  0.11591804,\n",
       "        -0.7039937 , -0.74087286, -0.9419614 , -0.1299069 ,  0.36697698,\n",
       "         0.28571236,  0.18357691, -0.07481738,  0.70810956, -0.34833708,\n",
       "         0.3977716 , -0.0052876 , -0.9963983 ,  0.00755792, -0.8277434 ,\n",
       "        -0.87234837, -0.99812734, -0.968761  ,  0.95261616, -0.18771593,\n",
       "         0.57118946, -0.32736477,  0.24455218,  0.7368634 ,  0.98597074,\n",
       "         0.91146356, -0.08467788, -0.47767213,  0.05579866, -0.3818684 ,\n",
       "         0.00181275,  0.34116724, -0.9885096 ,  0.9840008 , -0.3826358 ,\n",
       "         0.8774427 ,  0.99778134, -0.949097  , -0.4470819 ,  0.87773424,\n",
       "         0.89483607,  0.30457038, -0.827978  , -0.47439003, -0.21269062,\n",
       "         0.22699176,  0.74720985,  0.95810485,  0.88527066,  0.83011645,\n",
       "         0.6317664 , -0.966091  , -0.4234635 , -0.9608893 ],\n",
       "       [ 0.07565518, -0.98694766,  0.99252206,  0.2690276 ,  0.86997247,\n",
       "         0.19042572,  0.00393439, -0.47226408, -0.6442498 , -0.8163755 ,\n",
       "         0.3780827 , -0.80253875, -0.04233212,  0.03243667, -0.29491264,\n",
       "         0.04649943,  0.21774597,  0.1604435 ,  0.18241768, -0.9074424 ,\n",
       "         0.65290034, -0.84401983, -0.28469196, -0.03532499,  0.9778477 ,\n",
       "        -0.49104184, -0.6046648 ,  0.8836762 ,  0.47385192,  0.15676633,\n",
       "         0.65872264,  0.97478765, -0.83669657, -0.45073515,  0.27536836,\n",
       "        -0.94776905, -0.7770257 , -0.8021041 , -0.8331194 ,  0.93239534,\n",
       "        -0.9319198 , -0.4272001 , -0.09464602,  0.54603463,  0.90200216,\n",
       "        -0.16118346, -0.9860444 , -0.56716037,  0.8315608 ,  0.5969537 ,\n",
       "         0.55294615, -0.7648303 ,  0.73371136,  0.44524843, -0.23728248,\n",
       "        -0.6852466 ,  0.19667266, -0.95056504, -0.55949235, -0.750595  ,\n",
       "        -0.9823628 , -0.74463683, -0.9239825 ,  0.00430119]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 80, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,80,100])\n",
    "xt = x[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell0 = layers.SimpleRNNCell(64)\n",
    "cell1 = layers.SimpleRNNCell(64)\n",
    "h0 = [tf.zeros([4,64])]\n",
    "h1 = [tf.zeros([4,64])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xt in tf.unstack(x, axis=1):\n",
    "    out0, h0 = cell0(xt, h0)\n",
    "    out1, h0 = cell1(out0, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_sequences = []\n",
    "for xt in tf.unstack(x, axis = 1):\n",
    "    out0, h0 = cell0(xt, h0)\n",
    "    middle_sequences.append(out0)\n",
    "for xt in middle_sequences:\n",
    "    out1, h1 = cell1(xt, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.SimpleRNN(64)\n",
    "x = tf.random.normal([4,80,100])\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 80, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.SimpleRNN(64, return_sequences=True)\n",
    "x = tf.random.normal([4,80,100])\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = k.Sequential([\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(64),\n",
    "])\n",
    "out = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Users/zhangyunfei_06/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/zhangyunfei_06/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "total_words = 10000\n",
    "max_review_len = 80\n",
    "embedding_len = 100\n",
    "(x_train, y_train), (x_test, y_test) = k.datasets.imdb.load_data(num_words=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) 218 (25000,)\n",
      "(25000,) 68 (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, len(x_train[0]), y_train.shape)\n",
    "print(x_test.shape, len(x_test[0]), y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = k.datasets.imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i,\"?\") for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = k.preprocessing.sequence.pad_sequences(x_train,maxlen=max_review_len)\n",
    "x_test = k.preprocessing.sequence.pad_sequences(x_test,maxlen=max_review_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test_shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "db_train = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "db_train = db_train.shuffle(1000).batch(batch_size,drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "db_test = db_test.batch(batch_size,drop_remainder=True)\n",
    "print(\"x_train_shape:\",x_train.shape, tf.reduce_max(y_train),tf.reduce_min(y_train))\n",
    "print(\"x_test_shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "195/195 [==============================] - 11s 36ms/step - loss: 0.7054 - accuracy: 0.5099 - val_loss: 0.6816 - val_accuracy: 0.5960\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 6s 29ms/step - loss: 0.5783 - accuracy: 0.6942 - val_loss: 0.4138 - val_accuracy: 0.8169\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 6s 30ms/step - loss: 0.3910 - accuracy: 0.8355 - val_loss: 0.3870 - val_accuracy: 0.8289\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.3113 - accuracy: 0.8771 - val_loss: 0.4980 - val_accuracy: 0.8107\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.2480 - accuracy: 0.9043 - val_loss: 0.4952 - val_accuracy: 0.8195\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.1838 - accuracy: 0.9313 - val_loss: 0.6103 - val_accuracy: 0.8069\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.1476 - accuracy: 0.9463 - val_loss: 0.6188 - val_accuracy: 0.8050\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 0.1461 - accuracy: 0.9474 - val_loss: 0.5910 - val_accuracy: 0.7862\n",
      "Epoch 9/20\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 0.1143 - accuracy: 0.9587 - val_loss: 0.7873 - val_accuracy: 0.8107\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 6s 33ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.8099 - val_accuracy: 0.8101\n",
      "Epoch 11/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.0717 - accuracy: 0.9760 - val_loss: 0.8392 - val_accuracy: 0.7937\n",
      "Epoch 12/20\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 0.0594 - accuracy: 0.9786 - val_loss: 0.8906 - val_accuracy: 0.8035\n",
      "Epoch 13/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 0.9474 - val_accuracy: 0.7867\n",
      "Epoch 14/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 0.9798 - val_accuracy: 0.7925\n",
      "Epoch 15/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.8737 - val_accuracy: 0.8020\n",
      "Epoch 16/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.9596 - val_accuracy: 0.8091\n",
      "Epoch 17/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.0460 - accuracy: 0.9843 - val_loss: 0.8688 - val_accuracy: 0.8008\n",
      "Epoch 18/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.0394 - accuracy: 0.9861 - val_loss: 1.0621 - val_accuracy: 0.8042\n",
      "Epoch 19/20\n",
      "195/195 [==============================] - 6s 31ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 1.0301 - val_accuracy: 0.7950\n",
      "Epoch 20/20\n",
      "195/195 [==============================] - 6s 32ms/step - loss: 0.0411 - accuracy: 0.9851 - val_loss: 1.0253 - val_accuracy: 0.7923\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 1.0253 - accuracy: 0.7923\n"
     ]
    }
   ],
   "source": [
    "class MyRNN(k.Model):\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.state0 = [tf.zeros([batch_size,units])]\n",
    "        self.state1 = [tf.zeros([batch_size,units])]\n",
    "        self.embedding = layers.Embedding(total_words,embedding_len,input_length=max_review_len)\n",
    "        # 构建2个Cell\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        # 构建分类网络，用于将CELL的输出特征进行分类，2分类\n",
    "        # [b, 80, 100] => [b, 64] => [b, 1]\n",
    "        self.outlayer = Sequential([\n",
    "        \tlayers.Dense(units),\n",
    "        \tlayers.Dropout(rate=0.5),\n",
    "        \tlayers.ReLU(),\n",
    "        \tlayers.Dense(1)])\n",
    "        \n",
    "    def call(self, inputs, training = None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        state0 = self.state0\n",
    "        state1 = self.state1\n",
    "        for word in tf.unstack(x, axis=1):\n",
    "            out0, state0 = self.rnn_cell0(word, state0, training)\n",
    "            out1, state1 = self.rnn_cell1(out0, state1, training)\n",
    "        x = self.outlayer(out1, training)\n",
    "        prob = tf.sigmoid(x)\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "def main():\n",
    "    units = 64\n",
    "    epochs = 20\n",
    "    model = MyRNN(units)\n",
    "    model.compile(optimizer=optimizers.Adam(0.001),loss=losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "    model.fit(db_train, epochs = epochs, validation_data=db_test)\n",
    "    model.evaluate(db_test)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.ones([2,2])\n",
    "eigenvalues = tf.linalg.eigh(W)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = [W]\n",
    "for i in range(10):\n",
    "    val.append(val[-1]@W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fddd4ae6400>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm = list(map(lambda x:tf.norm(x).numpy(),val))\n",
    "plt.plot(range(1,12),norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.46585858, 0.6       ],\n",
       "       [0.6       , 0.4       ]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform([2,2])\n",
    "tf.clip_by_value(a,0.4,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=6.1137547>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform([2,2]) * 5\n",
    "b = tf.clip_by_norm(a,5)\n",
    "tf.norm(a),tf.norm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.377584, shape=(), dtype=float32) tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.random.normal([3,3])\n",
    "w2 = tf.random.normal([3,3])\n",
    "global_norm = tf.math.sqrt(tf.norm(w1)**2 + tf.norm(w2)**2)\n",
    "(ww1,ww2), global_norm = tf.clip_by_global_norm([w1,w2],2)\n",
    "global_norm2 = tf.math.sqrt(tf.norm(ww1)**2 + tf.norm(ww2)**2)\n",
    "print(global_norm,global_norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74458c41835937844e58948053197faf1f4659837a58f0a712ebbe1f2a1eca4b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
