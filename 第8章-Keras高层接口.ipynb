{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.6590012  0.24243298 0.09856589], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0.6590012  0.24243298 0.09856589], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([2, 1, 0.1])\n",
    "layer = layers.Softmax(axis = -1)\n",
    "# print(layer)\n",
    "out = layer(x)\n",
    "print(out)\n",
    "out = tf.nn.softmax(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.4878637  0.05905623]\n",
      " [0.08357453 0.        ]\n",
      " [1.4413633  0.174478  ]\n",
      " [1.0559056  0.12781808]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "network = Sequential([\n",
    "    layers.Dense(3, activation=None),\n",
    "    layers.ReLU(),\n",
    "    layers.Dense(2, activation=None),\n",
    "    layers.ReLU()\n",
    "])\n",
    "x = tf.random.normal([4, 3])\n",
    "out = network(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (4, 3)                    15        \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (4, 3)                    0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (4, 3)                    12        \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (4, 3)                    0         \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers_num = 2\n",
    "network = Sequential()\n",
    "for _ in range(layers_num):\n",
    "    network.add(layers.Dense(3))\n",
    "    network.add(layers.ReLU())\n",
    "network.build(input_shape=(4, 4))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_2/kernel:0 (4, 3)\n",
      "dense_2/bias:0 (3,)\n",
      "dense_3/kernel:0 (3, 3)\n",
      "dense_3/bias:0 (3,)\n"
     ]
    }
   ],
   "source": [
    "for p in network.trainable_variables:\n",
    "    print(p.name, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datesets: (60000, 28, 28) (60000,) 0 255\n",
      "(128, 784) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers, losses, datasets, Sequential, metrics\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [28*28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print(\"datesets:\", x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "\n",
    "sample = next(iter(db))\n",
    "print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (4, 256)                  200960    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (4, 128)                  32896     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (4, 64)                   8256      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (4, 32)                   2080      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (4, 10)                   330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([\n",
    "    layers.Dense(256, activation = 'relu'),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    layers.Dense(10)    \n",
    "])\n",
    "network.build(input_shape = (4, 28 * 28))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 0.5073 - accuracy: 0.8367\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1314 - accuracy: 0.9615 - val_loss: 0.1320 - val_accuracy: 0.9652\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 0.1066 - accuracy: 0.9693\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0893 - accuracy: 0.9755 - val_loss: 0.1204 - val_accuracy: 0.9702\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 0.0766 - accuracy: 0.9788\n"
     ]
    }
   ],
   "source": [
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "               loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "history = network.fit(db, epochs=5, validation_data=ds_val, validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12408343702554703, 0.9688000082969666]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[3 8 2 4 9 5 1 7 6 2 2 7 2 3 5 6 7 6 0 2 1 3 4 8 0 4 4 5 9 7 9 2 4 1 8 7 3\n",
      " 4 1 5 6 7 3 1 1 2 9 2 9 0 6 5 3 5 3 9 1 2 2 8 4 8 3 4 3 2 6 1 3 5 1 1 8 2\n",
      " 8 1 6 7 2 6 2 7 3 9 2 9 5 9 4 2 4 2 8 5 3 9 0 4 8 0 5 1 9 4 4 1 4 1 4 0 0\n",
      " 1 2 5 5 9 9 7 9 3 6 7 3 0 0 8 9 1], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[3 8 2 4 9 5 1 7 6 2 2 7 2 3 5 4 7 6 0 2 1 3 4 8 0 4 4 5 9 7 9 2 4 1 8 7 3\n",
      " 4 1 5 6 7 3 1 1 2 9 2 9 0 6 5 3 5 3 9 1 2 2 8 4 8 3 4 3 2 6 1 3 5 1 1 8 2\n",
      " 8 1 6 7 2 6 2 7 3 9 2 9 5 9 4 2 4 2 8 5 3 9 0 4 8 0 5 1 9 4 4 1 4 1 4 0 0\n",
      " 1 2 5 5 9 9 7 9 3 6 7 3 0 0 8 9 1], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(ds_val))\n",
    "x = sample[0]\n",
    "y = sample[1] # one-hot\n",
    "pred = network.predict(x) # [b, 10]\n",
    "# convert back to number \n",
    "y = tf.argmax(y, axis=1)\n",
    "pred = tf.argmax(pred, axis=1)\n",
    "\n",
    "print(pred)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.27798792719841003,\n",
       "  0.13113759458065033,\n",
       "  0.1109216958284378,\n",
       "  0.0910920724272728,\n",
       "  0.0814114436507225],\n",
       " 'accuracy': [0.9167166948318481,\n",
       "  0.9621333479881287,\n",
       "  0.96875,\n",
       "  0.9749666452407837,\n",
       "  0.977733314037323],\n",
       " 'val_loss': [0.13199099898338318, 0.12044104188680649],\n",
       " 'val_accuracy': [0.9652000069618225, 0.9702000021934509]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved weights.\n"
     ]
    }
   ],
   "source": [
    "network.save_weights(\"weights.ckpt\")\n",
    "print(\"saved weights.\")\n",
    "del network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights!\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([\n",
    "    layers.Dense(256, activation = 'relu'),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    layers.Dense(10)    \n",
    "])\n",
    "network.build(input_shape = (4, 28 * 28))\n",
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "               loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "network.load_weights(\"weights.ckpt\")\n",
    "print(\"loaded weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved total model.\n"
     ]
    }
   ],
   "source": [
    "network.save(\"model.h5\")\n",
    "print(\"saved total model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "network = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model-savedmodel/assets\n",
      "saving savedmodel.\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(network, \"model-savedmodel\")\n",
    "print(\"saving savedmodel.\")\n",
    "# del network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accucary:0.968800\n"
     ]
    }
   ],
   "source": [
    "# print(\"load savedmodel from file.\")\n",
    "# network = tf.saved_model.load(\"model-savedmodel\")\n",
    "acc_meter = metrics.CategoricalAccuracy()\n",
    "for x, y in ds_val:\n",
    "    pred = network(x)\n",
    "    acc_meter.update_state(y_true=y, y_pred=pred)\n",
    "print(\"Test Accucary:%f\" % acc_meter.result())\n",
    "# network.predict(next(iter(ds_val))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load savedmodel from file.\n"
     ]
    }
   ],
   "source": [
    "print(\"load savedmodel from file.\")\n",
    "network_save = tf.saved_model.load(\"model-savedmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Variable 'w:0' shape=(4, 3) dtype=float32, numpy=\n",
       "  array([[-0.5406294 , -0.64397204, -0.3079378 ],\n",
       "         [ 0.84875655, -0.889512  , -0.25044334],\n",
       "         [ 0.6833739 , -0.7910568 , -0.8927294 ],\n",
       "         [-0.6951215 , -0.02482361, -0.10442203]], dtype=float32)>],\n",
       " [<tf.Variable 'w:0' shape=(4, 3) dtype=float32, numpy=\n",
       "  array([[-0.5406294 , -0.64397204, -0.3079378 ],\n",
       "         [ 0.84875655, -0.889512  , -0.25044334],\n",
       "         [ 0.6833739 , -0.7910568 , -0.8927294 ],\n",
       "         [-0.6951215 , -0.02482361, -0.10442203]], dtype=float32)>])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        self.kernel = self.add_weight('w', [inp_dim,outp_dim], trainable = True)\n",
    "        \n",
    "net = MyDense(4, 3)\n",
    "net.variables, net.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Variable 'w:0' shape=(4, 3) dtype=float32, numpy=\n",
       "  array([[-0.39678138,  0.64084554,  0.4118085 ],\n",
       "         [-0.7462772 ,  0.37606716, -0.52723336],\n",
       "         [ 0.7721833 ,  0.05772781, -0.33982682],\n",
       "         [ 0.32219386,  0.06628978, -0.07225043]], dtype=float32)>],\n",
       " [])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        self.kernel = self.add_weight('w', [inp_dim,outp_dim], trainable = False)\n",
    "        \n",
    "net = MyDense(4, 3)\n",
    "net.variables, net.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
       "  array([[ 0.40682504, -0.7767524 ,  0.3755346 ],\n",
       "         [ 0.58661646, -0.6782297 ,  1.0860798 ],\n",
       "         [-0.06641417,  0.63832235, -1.3410153 ],\n",
       "         [ 0.73147297,  0.18757865, -0.33223808]], dtype=float32)>],\n",
       " [])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        self.kernel = tf.Variable(tf.random.normal([inp_dim,outp_dim]), trainable = False)\n",
    "    \n",
    "    def call(self, inputs, training = None):\n",
    "        out = inputs @ self.kernel\n",
    "        out = tf.nn.relu(out)\n",
    "        return out\n",
    "        \n",
    "net = MyDense(4, 3)\n",
    "net.variables, net.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 10) 0 255\n",
      "batch: (128, 32, 32, 3) (128, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangyunfei_06/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.8469 - accuracy: 0.3423 - val_loss: 1.5662 - val_accuracy: 0.4525\n",
      "Epoch 2/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.5271 - accuracy: 0.4583 - val_loss: 1.4781 - val_accuracy: 0.4735\n",
      "Epoch 3/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.4122 - accuracy: 0.5003 - val_loss: 1.4459 - val_accuracy: 0.4912\n",
      "Epoch 4/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.3336 - accuracy: 0.5299 - val_loss: 1.4341 - val_accuracy: 0.4970\n",
      "Epoch 5/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.2636 - accuracy: 0.5506 - val_loss: 1.4340 - val_accuracy: 0.5021\n",
      "Epoch 6/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.1958 - accuracy: 0.5748 - val_loss: 1.4547 - val_accuracy: 0.5112\n",
      "Epoch 7/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.1337 - accuracy: 0.6060 - val_loss: 1.4046 - val_accuracy: 0.5207\n",
      "Epoch 8/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0707 - accuracy: 0.6217 - val_loss: 1.4145 - val_accuracy: 0.5233\n",
      "Epoch 9/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.0223 - accuracy: 0.6395 - val_loss: 1.4714 - val_accuracy: 0.5121\n",
      "Epoch 10/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9655 - accuracy: 0.6607 - val_loss: 1.4816 - val_accuracy: 0.5183\n",
      "Epoch 11/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9184 - accuracy: 0.6780 - val_loss: 1.4986 - val_accuracy: 0.5186\n",
      "Epoch 12/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8714 - accuracy: 0.6927 - val_loss: 1.5391 - val_accuracy: 0.5196\n",
      "Epoch 13/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8239 - accuracy: 0.7095 - val_loss: 1.5674 - val_accuracy: 0.5181\n",
      "Epoch 14/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7788 - accuracy: 0.7278 - val_loss: 1.6096 - val_accuracy: 0.5200\n",
      "Epoch 15/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7440 - accuracy: 0.7363 - val_loss: 1.6861 - val_accuracy: 0.5237\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.6861 - accuracy: 0.5237\n",
      "saved to ckpt/weights.ckpt\n",
      "loaded weights from file.\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 1.6854 - accuracy: 0.5238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.686081051826477, 0.5236999988555908]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    # [0~255] => [-1~1]\n",
    "    x = 2 * tf.cast(x, dtype=tf.float32) / 255. - 1.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "batchsz = 128\n",
    "# [50k, 32, 32, 3], [10k, 1]\n",
    "(x, y), (x_val, y_val) = datasets.cifar10.load_data()\n",
    "y = tf.squeeze(y)\n",
    "y_val = tf.squeeze(y_val)\n",
    "y = tf.one_hot(y, depth=10) # [50k, 10]\n",
    "y_val = tf.one_hot(y_val, depth=10) # [10k, 10]\n",
    "print('datasets:', x.shape, y.shape, x_val.shape, y_val.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.map(preprocess).shuffle(10000).batch(batchsz)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "test_db = test_db.map(preprocess).batch(batchsz)\n",
    "\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print('batch:', sample[0].shape, sample[1].shape)\n",
    "\n",
    "\n",
    "class MyDense(layers.Layer):\n",
    "    # to replace standard layers.Dense()\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "\n",
    "        self.kernel = self.add_variable('w', [inp_dim, outp_dim])\n",
    "        # self.bias = self.add_variable('b', [outp_dim])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        x = inputs @ self.kernel\n",
    "        return x\n",
    "\n",
    "class MyNetwork(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "\n",
    "        self.fc1 = MyDense(32*32*3, 256)\n",
    "        self.fc2 = MyDense(256, 128)\n",
    "        self.fc3 = MyDense(128, 64)\n",
    "        self.fc4 = MyDense(64, 32)\n",
    "        self.fc5 = MyDense(32, 10)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param inputs: [b, 32, 32, 3]\n",
    "        :param training:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = tf.reshape(inputs, [-1, 32*32*3])\n",
    "        # [b, 32*32*3] => [b, 256]\n",
    "        x = self.fc1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        # [b, 256] => [b, 128]\n",
    "        x = self.fc2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        # [b, 128] => [b, 64]\n",
    "        x = self.fc3(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        # [b, 64] => [b, 32]\n",
    "        x = self.fc4(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        # [b, 32] => [b, 10]\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "network = MyNetwork()\n",
    "network.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "                loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "network.fit(train_db, epochs=15, validation_data=test_db, validation_freq=1)\n",
    "\n",
    "network.evaluate(test_db)\n",
    "network.save_weights('ckpt/weights.ckpt')\n",
    "del network\n",
    "print('saved to ckpt/weights.ckpt')\n",
    "\n",
    "\n",
    "network = MyNetwork()\n",
    "network.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "                loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "network.load_weights('ckpt/weights.ckpt')\n",
    "print('loaded weights from file.')\n",
    "network.evaluate(test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet = keras.applications.ResNet50(weights='imagenet', include_top = False)\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 7, 2048)\n",
      "(4, 2048)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([4, 224, 224, 3])\n",
    "out = resnet(x)\n",
    "print(out.shape)\n",
    "\n",
    "global_average_layer = layers.GlobalAveragePooling2D()\n",
    "x = tf.random.normal([4, 7, 7, 2048])\n",
    "out = global_average_layer(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 100)\n"
     ]
    }
   ],
   "source": [
    "fc = layers.Dense(100)\n",
    "x = tf.random.normal([4, 2048])\n",
    "out = fc(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, None, None, 2048)  23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               204900    \n",
      "=================================================================\n",
      "Total params: 23,792,612\n",
      "Trainable params: 23,739,492\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mynet = Sequential([resnet,global_average_layer,fc])\n",
    "mynet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_meter = metrics.Mean()\n",
    "loss_meter.update_state(float(loss))\n",
    "print(step, 'loss', loss_meter.result())\n",
    "loss_meter.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 loss: 2.3112218\n",
      "78 Evaluate Acc: 0.1622 0.1622\n",
      "100 loss: 0.54319376\n",
      "200 loss: 0.24618587\n",
      "300 loss: 0.20757149\n",
      "400 loss: 0.17517602\n",
      "500 loss: 0.16234052\n",
      "78 Evaluate Acc: 0.957 0.957\n",
      "600 loss: 0.14038473\n",
      "700 loss: 0.13164657\n",
      "800 loss: 0.12956536\n",
      "900 loss: 0.1359336\n",
      "1000 loss: 0.10840842\n",
      "78 Evaluate Acc: 0.9585 0.9585\n",
      "1100 loss: 0.11478761\n",
      "1200 loss: 0.10746125\n",
      "1300 loss: 0.10424265\n",
      "1400 loss: 0.13276224\n",
      "1500 loss: 0.09677818\n",
      "78 Evaluate Acc: 0.9661 0.9661\n",
      "1600 loss: 0.09573699\n",
      "1700 loss: 0.10579374\n",
      "1800 loss: 0.1148338\n",
      "1900 loss: 0.09936019\n",
      "2000 loss: 0.086166695\n",
      "78 Evaluate Acc: 0.9732 0.9732\n",
      "2100 loss: 0.08966437\n",
      "2200 loss: 0.09156335\n",
      "2300 loss: 0.08936841\n",
      "2400 loss: 0.08393867\n",
      "2500 loss: 0.08527522\n",
      "78 Evaluate Acc: 0.9755 0.9755\n",
      "2600 loss: 0.09338359\n",
      "2700 loss: 0.09043942\n",
      "2800 loss: 0.07374875\n",
      "2900 loss: 0.065836385\n",
      "3000 loss: 0.055926446\n",
      "78 Evaluate Acc: 0.9713 0.9713\n",
      "3100 loss: 0.07440835\n",
      "3200 loss: 0.079498336\n",
      "3300 loss: 0.08099177\n",
      "3400 loss: 0.061149746\n",
      "3500 loss: 0.0694526\n",
      "78 Evaluate Acc: 0.9741 0.9741\n",
      "3600 loss: 0.07437971\n",
      "3700 loss: 0.07513084\n",
      "3800 loss: 0.062676415\n",
      "3900 loss: 0.059367124\n",
      "4000 loss: 0.066737354\n",
      "78 Evaluate Acc: 0.9595 0.9595\n",
      "4100 loss: 0.05963036\n",
      "4200 loss: 0.06813947\n",
      "4300 loss: 0.067716084\n",
      "4400 loss: 0.048753932\n",
      "4500 loss: 0.056801945\n",
      "78 Evaluate Acc: 0.9762 0.9762\n",
      "4600 loss: 0.07134833\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "def preprocess(x, y):\n",
    "\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "acc_meter = metrics.Accuracy()\n",
    "loss_meter = metrics.Mean()\n",
    "\n",
    "\n",
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10) \n",
    "        # [b]\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "\n",
    "        loss_meter.update_state(loss)\n",
    "\n",
    " \n",
    "\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "\n",
    "    if step % 100 == 0:\n",
    "\n",
    "        print(step, 'loss:', loss_meter.result().numpy()) \n",
    "        loss_meter.reset_states()\n",
    "\n",
    "\n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        total, total_correct = 0., 0\n",
    "        acc_meter.reset_states()\n",
    "\n",
    "        for step, (x, y) in enumerate(ds_val): \n",
    "            # [b, 28, 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = network(x) \n",
    "\n",
    "\n",
    "            # [b, 10] => [b] \n",
    "            pred = tf.argmax(out, axis=1) \n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # bool type \n",
    "            correct = tf.equal(pred, y)\n",
    "            # bool tensor => int tensor => numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "\n",
    "            acc_meter.update_state(y, pred)\n",
    "\n",
    "\n",
    "        print(step, 'Evaluate Acc:', total_correct/total, acc_meter.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3642 - accuracy: 0.8892 - val_loss: 0.0916 - val_accuracy: 0.9723\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0911 - accuracy: 0.9717 - val_loss: 0.0899 - val_accuracy: 0.9733\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0609 - accuracy: 0.9813 - val_loss: 0.0748 - val_accuracy: 0.9786\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0448 - accuracy: 0.9855 - val_loss: 0.0673 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.0679 - val_accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcb71f06880>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 63294), started 0:05:57 ago. (Use '!kill 63294' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-34dee2d3df21c13\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-34dee2d3df21c13\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
